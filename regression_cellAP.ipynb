{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:14:16.936144Z",
     "start_time": "2021-11-25T13:14:13.294992Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, RepeatedKFold, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalAveragePooling1D, AveragePooling1D\n",
    "from tensorflow.keras.layers import Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "# import lime\n",
    "# import lime.lime_tabular\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = \"Helvetica\"\n",
    "plt.rcParams['font.family'] = \"sans-serif\"\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T12:30:21.963668Z",
     "start_time": "2021-11-25T12:30:20.340835Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'tf.test.is_built_with_cuda(): {tf.test.is_built_with_cuda()}')\n",
    "\n",
    "print(f'tf.test.is_gpu_available(): {tf.test.is_gpu_available()}')\n",
    "\n",
    "if tf.__version__[0] == '1':\n",
    "    print(f'tf.config.experimental_list_devices(): {tf.config.experimental_list_devices()}')\n",
    "else:\n",
    "    print(f'tf.config.list_physical_devices(\"GPU\"): {tf.config.list_physical_devices(\"GPU\")}')\n",
    "    \n",
    "print(f'tf.test.gpu_device_name(): {tf.test.gpu_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save keras model: https://www.tensorflow.org/guide/keras/save_and_serialize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:14:18.835998Z",
     "start_time": "2021-11-25T13:14:18.827149Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_my_results(results_mae, results_mae_per, results_r2, results_r2_per):\n",
    "    print('MAE:')\n",
    "    print('\\t%.3f (%.3f) overall' % (np.mean(results_mae), np.std(results_mae)))\n",
    "    for mae,std,idx in zip(np.mean(results_mae_per, axis=0), np.std(results_mae_per, axis=0), idxs):\n",
    "        print('\\t%.3f (%.3f) %s' % (mae, std, labels[idx]) )\n",
    "    print('R2:')\n",
    "    print('\\t%.3f (%.3f) overall' %(np.mean(results_r2), np.std(results_r2)))\n",
    "    for r2,std,idx in zip(np.mean(results_r2_per, axis=0), np.std(results_r2_per, axis=0), idxs):\n",
    "        print('\\t%.3f (%.3f) %s' % (r2, std, labels[idx]) )\n",
    "        \n",
    "        \n",
    "def save_my_results(results_mae):\n",
    "    my_fname = \"MLR_results_mae.csv\"\n",
    "    if not os.path.isfile(my_fname):\n",
    "        with open(my_fname,\"w\") as fp:\n",
    "            pass\n",
    "    with open(my_fname, \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(results_mae)\n",
    "        \n",
    "        \n",
    "def drop_features(X, n_segments=3, dropval=\"zero\"):\n",
    "    X_length = X.shape[1]\n",
    "    idx_full = np.arange(0,X_length)\n",
    "    idx_segments = np.array_split(idx_full, n_segments)\n",
    "    X_repeat = list()\n",
    "    for idx_seg in idx_segments:\n",
    "        X_drop = np.copy(X)\n",
    "        if dropval == \"zero\":\n",
    "            X_drop[:,idx_seg] = 0.0\n",
    "        elif dropval == \"mean\":\n",
    "            X_drop[:,idx_seg] = np.mean(X) # mean across both axes of X\n",
    "        X_repeat.append(X_drop)\n",
    "    return X_repeat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:14:23.182922Z",
     "start_time": "2021-11-25T13:14:23.154958Z"
    }
   },
   "outputs": [],
   "source": [
    "name = \"km-adjfactors_p11_s100_n5000_filtered3\"\n",
    "data_path = Path(f'./data_control_{name}.h5')\n",
    "\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    Datasetnames=f.keys()\n",
    "    print(*list(Datasetnames), sep = \"\\n\")\n",
    "    trace = f['trace'][:,:200,:] # select time 0-200\n",
    "    t = f['time'][...]\n",
    "    adj_factors = f['adjustment_factors'][...]\n",
    "    cost_terms = f['cost_terms'][...]\n",
    "    \n",
    "if trace.shape[0] != adj_factors.shape[0]:\n",
    "    print('Number of samples do not match for trace and adj_factors!')\n",
    "\n",
    "print(\"Number of traces:\", trace.shape[0])\n",
    "labels = [\"g_Kr\",\"g_CaL\",\"lambda_B\",\"g_NaCa\",\"g_K1\",\"J_SERCA_bar\",\"lambda_diff\",\"lambda_RyR\",\"g_bCa\",\"g_Na\",\"g_NaL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:14:34.828937Z",
     "start_time": "2021-11-25T13:14:34.826821Z"
    }
   },
   "outputs": [],
   "source": [
    "# randst = np.random.randint(0,100)\n",
    "# print(randst)\n",
    "randst = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T09:19:09.093552Z",
     "start_time": "2021-09-29T09:19:09.085654Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = [0,1,4,9]\n",
    "idx_targets = np.r_[idxs]\n",
    "\n",
    "X = np.concatenate((trace[:,:,0],trace[:,:,1]),axis=1)\n",
    "y = adj_factors[:,idx_targets]\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T09:19:32.371974Z",
     "start_time": "2021-09-29T09:19:32.364303Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_knn(n_neighbors=6):\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors,\n",
    "                                weights=\"uniform\", # default = uniform\n",
    "                                n_jobs=None)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model_knn(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # define and fit model\n",
    "        model = get_model_knn(n_neighbors=6)\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model on test set\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test, y_hat, multioutput='raw_values')\n",
    "        r2 = r2_score(y_test, y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T09:19:34.949500Z",
     "start_time": "2021-09-29T09:19:33.962059Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_knn(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (stop-start))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T13:24:57.418212Z",
     "start_time": "2021-09-14T13:24:57.300867Z"
    }
   },
   "outputs": [],
   "source": [
    "saveit = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randst)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = get_model_knn()\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "mae_of_mean = np.mean(np.abs(y_train.mean(axis=0) - y_test))\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Channel:\",[labels[i] for i in idxs])\n",
    "print(\"MAE:\", mae_per)\n",
    "print(\"R2:\", r2_per)\n",
    "# save_my_results(np.append(mae_per, [mae,mae_of_mean]))\n",
    "\n",
    "if saveit:\n",
    "    np.save('../results/kNN_predicted_p4.npy',y_hat)\n",
    "    np.save('../results/kNN_true_p4.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T20:13:33.940011Z",
     "start_time": "2021-08-16T20:13:33.390334Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = get_model_knn()\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(model, param_grid, cv=5)\n",
    "knn_gscv.fit(X, y)\n",
    "\n",
    "print(knn_gscv.best_params_)\n",
    "n_best = knn_gscv.best_params_[\"n_neighbors\"]\n",
    "\n",
    "model = get_model_knn(n_neighbors=n_best)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "r2 = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "print(\"MAE:\",mae)\n",
    "print(\"R2:\", r2)\n",
    "print([labels[i] for i in idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:42:31.306513Z",
     "start_time": "2021-09-21T14:42:31.297762Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = [0,1,4,9]\n",
    "# idxs = [0,1]\n",
    "idx_targets = np.r_[idxs]\n",
    "\n",
    "X = np.concatenate((trace[:,:,0],trace[:,:,1]),axis=1)\n",
    "y = adj_factors[:,idx_targets]\n",
    "feature_names = [f'feat_V {i}' for i in range(int(X.shape[1]/2))] + [f'feat_Ca {i}' for i in range(int(X.shape[1]/2))]\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:42:33.422909Z",
     "start_time": "2021-09-21T14:42:33.415618Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_rfr():\n",
    "    model = RandomForestRegressor()\n",
    "    return model\n",
    "\n",
    "def evaluate_model_rfr(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # define model\n",
    "        model = get_model_rfr()\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model on test set\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:54:38.001053Z",
     "start_time": "2021-09-21T14:42:37.900687Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_rfr(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T13:26:38.036672Z",
     "start_time": "2021-09-14T13:25:55.708909Z"
    }
   },
   "outputs": [],
   "source": [
    "saveit = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randst)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = get_model_rfr()\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "mae_of_mean = np.mean(np.abs(y_train.mean(axis=0) - y_test))\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Channel:\",[labels[i] for i in idxs])\n",
    "print(\"MAE:\", mae_per)\n",
    "print(\"R2:\", r2_per)\n",
    "# save_my_results(np.append(mae_per, [mae,mae_of_mean]))\n",
    "\n",
    "if saveit:\n",
    "    np.save('../results/rfr_predicted_p4.npy',y_hat)\n",
    "    np.save('../results/rfr_true_p4.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T14:47:54.530475Z",
     "start_time": "2021-09-06T14:47:53.065287Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = model.feature_importances_\n",
    "# plt.bar([x for x in range(len(importance))], importance)\n",
    "\n",
    "rf_importances = pd.Series(importance, index=feature_names)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(14,4))\n",
    "rf_importances.plot.bar(ax=ax, width=1)\n",
    "tick_spacing = 10\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:59:41.853461Z",
     "start_time": "2021-09-21T14:59:41.844118Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = [0,1,4,9]\n",
    "idx_targets = np.r_[idxs]\n",
    "\n",
    "X = np.concatenate((trace[:,:,0],trace[:,:,1]),axis=1)\n",
    "y = adj_factors[:,idx_targets]\n",
    "# y = adj_factors[:,:]\n",
    "feature_names = [f'feat_V {i}' for i in range(int(X.shape[1]/2))] + [f'feat_Ca {i}' for i in range(int(X.shape[1]/2))]\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:59:51.066419Z",
     "start_time": "2021-09-21T14:59:51.058248Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_svr():\n",
    "    svr = SVR(kernel='rbf',\n",
    "          C=100.0,\n",
    "          epsilon=0.01,\n",
    "          gamma=0.001\n",
    "         )\n",
    "\n",
    "    model = MultiOutputRegressor(svr)\n",
    "    return model\n",
    "\n",
    "def evaluate_model_svr(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # define model\n",
    "        model = get_model_svr()\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model on test set\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T15:10:10.439455Z",
     "start_time": "2021-09-21T15:00:45.616919Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_svr(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T13:29:35.893867Z",
     "start_time": "2021-09-14T13:28:58.660031Z"
    }
   },
   "outputs": [],
   "source": [
    "saveit = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randst)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = get_model_svr()\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "mae_of_mean = np.mean(np.abs(y_train.mean(axis=0) - y_test))\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Channel:\",[labels[i] for i in idxs])\n",
    "print(\"MAE:\", mae_per)\n",
    "print(\"R2:\", r2_per)\n",
    "# save_my_results(np.append(mae_per, [mae,mae_of_mean]))\n",
    "\n",
    "if saveit:\n",
    "    np.save('../results/svr_predicted_p11.npy',y_hat)\n",
    "    np.save('../results/svr_true_p11.npy',y_test)\n",
    "    np.savetxt('../results/svr_target_p11.csv',y_test,delimiter=',',fmt='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T12:34:20.428239Z",
     "start_time": "2021-11-25T12:34:20.418387Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = [0,1,4,9]\n",
    "idx_targets = np.r_[idxs]\n",
    "\n",
    "X = np.concatenate((trace[:,:,0],trace[:,:,1]),axis=1)\n",
    "y = adj_factors[:,idx_targets]\n",
    "feature_names = [f'feat_V_{i}' for i in range(int(X.shape[1]/2))] + [f'feat_Ca_{i}' for i in range(int(X.shape[1]/2))]\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T12:34:22.676077Z",
     "start_time": "2021-11-25T12:34:22.667039Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_mlp1(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=n_inputs, kernel_initializer='he_uniform', activation=activations.swish))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=\"mae\")\n",
    "    return model\n",
    "\n",
    "def get_model_mlp3(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=n_inputs, kernel_initializer='he_uniform', activation=activations.swish))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(500, activation=activations.swish))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(500, activation=activations.swish))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=\"mae\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model_mlp(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        model = get_model_mlp3(n_inputs, n_outputs) # <<<<< SPECIFY WHICH MLP MODEL\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, verbose=0)\n",
    "#         model.fit(X_train, y_train, verbose=0, epochs=200) # default epochs=100\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T12:40:49.289790Z",
     "start_time": "2021-11-25T12:34:25.572117Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_mlp(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f min' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T13:31:16.856814Z",
     "start_time": "2021-09-14T13:30:28.664012Z"
    }
   },
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randst)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "keras_spec = 0\n",
    "if keras_spec:\n",
    "    model = KerasRegressor(build_fn=lambda: get_model_mlp(n_inputs, n_outputs), epochs=200, verbose=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "else:\n",
    "    model = get_model_mlp(n_inputs, n_outputs)\n",
    "    model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "#     history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "mae_of_mean = np.mean(np.abs(y_train.mean(axis=0) - y_test))\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Channel:\",[labels[i] for i in idxs])\n",
    "print(\"MAE:\", mae_per)\n",
    "print(\"R2:\", r2_per)\n",
    "# save_my_results(np.append(mae_per, [mae,mae_of_mean]))\n",
    "\n",
    "# np.save('../results/mlp_predicted_p4.npy',y_hat)\n",
    "# np.save('../results/mlp_true_p4.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T12:36:22.373314Z",
     "start_time": "2021-09-09T12:36:22.236359Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['mae'], label='train')\n",
    "plt.plot(history.history['val_mae'], label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss (MAE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T12:44:48.201332Z",
     "start_time": "2021-11-25T12:44:48.191214Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = [0,1,4,9]\n",
    "# idxs = [0]\n",
    "idx_targets = np.r_[idxs]\n",
    "\n",
    "X = np.copy(trace)\n",
    "y = adj_factors[:,idx_targets]\n",
    "feature_names = [f'feat_V {i}' for i in range(X.shape[1])] + [f'feat_Ca {i}' for i in range(X.shape[1])]\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T12:45:02.634660Z",
     "start_time": "2021-11-25T12:45:02.627010Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_cnn(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, input_shape=n_inputs))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation=activations.swish))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def evaluate_model_cnn(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    n_inputs, n_outputs = X.shape[1:], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scalers = {}\n",
    "        for i in range(X_train.shape[2]):\n",
    "            scalers[i] = StandardScaler()\n",
    "            X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "        for i in range(X_test.shape[2]):\n",
    "            X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])\n",
    "        model = get_model_cnn(n_inputs, n_outputs)\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=200)\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T12:51:42.564057Z",
     "start_time": "2021-11-25T12:45:29.959103Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_cnn(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f min' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T11:30:36.455273Z",
     "start_time": "2021-09-09T11:30:15.516264Z"
    }
   },
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X.shape[1:], y.shape[1]\n",
    "\n",
    "# prep data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randst)\n",
    "n_batch, n_time, n_channel  = X_train.shape[0], X_train.shape[1], X_train.shape[2]\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])\n",
    "\n",
    "# train and test model\n",
    "model = get_model_cnn(n_inputs, n_outputs)\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, verbose=1)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "mae_of_mean = np.mean(np.abs(y_train.mean(axis=0) - y_test))\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Channel:\",[labels[i] for i in idxs])\n",
    "print(\"MAE:\", mae_per)\n",
    "print(\"R2:\", r2_per)\n",
    "save_my_results(np.append(mae_per, [mae,mae_of_mean]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Neural Networks (FCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:14:42.380351Z",
     "start_time": "2021-11-25T13:14:42.370860Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = [0,1,4,9]\n",
    "idx_targets = np.r_[idxs]\n",
    "\n",
    "X = np.copy(trace)\n",
    "y = adj_factors[:,idx_targets]\n",
    "feature_names = [f'feat_V {i}' for i in range(X.shape[1])] + [f'feat_Ca {i}' for i in range(X.shape[1])]\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:14:44.047929Z",
     "start_time": "2021-11-25T13:14:44.035198Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_fcn(n_inputs, n_outputs):\n",
    "    x = keras.layers.Input(n_inputs)\n",
    "    drop_out = Dropout(0.1)(x)\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=8, input_shape=n_inputs, padding='same')(x) # default filter 128\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activations.swish)(conv1)\n",
    "\n",
    "    drop_out = Dropout(0.1)(conv1)\n",
    "    conv2 = keras.layers.Conv1D(filters=128, kernel_size=5, padding='same')(conv1) # default filter 256\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.Activation(activations.swish)(conv2)\n",
    "\n",
    "    drop_out = Dropout(0.1)(conv2)\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding='same')(conv2) # default filter 128\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.Activation(activations.swish)(conv3)\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "#     full = keras.layers.GlobalMaxPooling1D()(conv3)\n",
    "    out = keras.layers.Dense(n_outputs)(full)\n",
    "    model = keras.models.Model(inputs=x, outputs=out)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def get_model_fcn_2(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=128, kernel_size=8, input_shape=n_inputs, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=256, kernel_size=5, input_shape=n_inputs, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, input_shape=n_inputs, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "#     model.add(MaxPooling1D())\n",
    "#     model.add(AveragePooling1D())\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "    \n",
    "def evaluate_model_fcn(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    n_inputs, n_outputs = X.shape[1:], y.shape[1]\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        X_train, X_test = X[train_ix,:,:], X[test_ix,:,:]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        nbatch, n_time, n_channel  = X_train.shape[0], X_train.shape[1], X_train.shape[2]\n",
    "        scalers = {}\n",
    "        for i in range(X_train.shape[2]):\n",
    "            scalers[i] = StandardScaler()\n",
    "            X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "        for i in range(X_test.shape[2]):\n",
    "            X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])\n",
    "        model = get_model_fcn(n_inputs, n_outputs)\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=200) # default epochs=100\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:29:54.102299Z",
     "start_time": "2021-11-25T13:14:54.176643Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_fcn(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T11:39:02.850836Z",
     "start_time": "2021-09-09T11:31:38.823509Z"
    }
   },
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X.shape[1:], y.shape[1]\n",
    "\n",
    "# prep data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randst)\n",
    "n_batch, n_time, n_channel  = X_train.shape[0], X_train.shape[1], X_train.shape[2]\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])\n",
    "\n",
    "# train and test model\n",
    "model = get_model_fcn(n_inputs, n_outputs)\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, verbose=1)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "mae_of_mean = np.mean(np.abs(y_train.mean(axis=0) - y_test))\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Channel:\",[labels[i] for i in idxs])\n",
    "print(\"MAE:\", mae_per)\n",
    "print(\"R2:\", r2_per)\n",
    "save_my_results(np.append(mae_per, [mae,mae_of_mean]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T21:18:07.348965Z",
     "start_time": "2021-08-13T21:18:07.031038Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['mae'], label='train')\n",
    "plt.plot(history.history['val_mae'], label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss (MAE)')\n",
    "plt.savefig('/Users/nick/Desktop/FCN_training_history_nb200.png',dpi=200,bbox_inches='tight')\n",
    "# plt.title('lrate='+str(lrate), pad=-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T22:13:51.517991Z",
     "start_time": "2021-07-29T22:13:51.501053Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = [0,1,4,9,10]\n",
    "idx_targets = np.r_[idxs]\n",
    "\n",
    "X = trace\n",
    "y = adj_factors[:,idx_targets]\n",
    "feature_names = [f'feat_V {i}' for i in range(X.shape[1])] + [f'feat_Ca {i}' for i in range(X.shape[1])]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[:,:,0] = scaler.fit_transform(X[:,:,0])\n",
    "X[:,:,1] = scaler.fit_transform(X[:,:,1])\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T22:55:47.180496Z",
     "start_time": "2021-08-11T22:55:47.173749Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_lstm(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=64, batch_input_shape=n_inputs, return_sequences=True)))\n",
    "    model.add(LSTM(units=64))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def evaluate_model_lstm(X, y):\n",
    "    results_mae = list()\n",
    "    results_r2 = list()\n",
    "    n_inputs, n_outputs = X.shape[1:], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # define model\n",
    "        model = get_model_lstm(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=200) # default epochs=100\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2 = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2_all = r2_score(y_test,y_hat)\n",
    "        # evaluate model on test set\n",
    "        mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae_all.append(mae)\n",
    "        results_r2_all.append(r2_all)\n",
    "        results_r2.append(r2)\n",
    "    return results_mae_all, results_r2_all, results_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T22:55:48.191325Z",
     "start_time": "2021-08-11T22:55:48.146756Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae_all, results_r2_all, results_r2 = evaluate_model_lstm(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (stop-start))\n",
    "\n",
    "print_my_results(results_mae_all, results_r2_all, results_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T23:24:23.091568Z",
     "start_time": "2021-07-29T23:20:13.660935Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randst)\n",
    "model = get_model_lstm(X.shape, y.shape[1])\n",
    "\n",
    "nb_epoch = 200\n",
    "for i in tqdm(range(nb_epoch)):\n",
    "    model.fit(X_train, y_train, epochs=1, shuffle=False, verbose=0)\n",
    "    model.reset_states()\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "y_hat = model.predict(X_test)\n",
    "r2 = r2_score(y_test,y_hat)\n",
    "mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(mae)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable algorithms\n",
    "\n",
    "Start with a trained model, train dataset, test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME (local interpretable model-agnostic explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular data (2d array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T14:22:12.436354Z",
     "start_time": "2021-09-07T14:22:12.236791Z"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names, verbose=True, mode='regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T14:24:49.648558Z",
     "start_time": "2021-09-07T14:22:22.691766Z"
    }
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(0, X_test.shape[0])\n",
    "exp = explainer.explain_instance(X_test[i], model.predict, num_features=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-channel data (3d array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T18:27:43.884584Z",
     "start_time": "2021-09-02T18:27:43.859152Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = [str(i) for i in np.arange(X_train.shape[1])]\n",
    "\n",
    "explainer = lime.lime_tabular.RecurrentTabularExplainer(X_train, feature_names=feature_names, \n",
    "                                                        verbose=True, mode='regression', discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T18:27:44.924905Z",
     "start_time": "2021-09-02T18:27:44.511430Z"
    }
   },
   "outputs": [],
   "source": [
    "n_targets = y_train.shape[1]\n",
    "i = np.random.randint(0,X_test.shape[0])\n",
    "exp = explainer.explain_instance(X_test[i], model.predict, num_features=400, num_samples=5000)\n",
    "    \n",
    "# exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T18:32:36.573302Z",
     "start_time": "2021-09-02T18:32:36.556532Z"
    }
   },
   "outputs": [],
   "source": [
    "explanations = exp.as_list()\n",
    "\n",
    "# extract feature identifier and sort\n",
    "import re\n",
    "list1a, list2a = zip(*explanations)\n",
    "list1b = [re.split('_|-',a) for a in list1a]\n",
    "list1c, list1d, list1e = zip(*list1b)\n",
    "\n",
    "my_list = []\n",
    "for m in range(len(explanations)):\n",
    "    row = [int(list1c[m]), int(list1e[m]), list2a[m]]\n",
    "    my_list.append(row)\n",
    "\n",
    "my_df = pd.DataFrame(data=my_list,columns=['feature','time','weight'])\n",
    "my_df[\"time\"] = 200-my_df[\"time\"] # TIME IS REPRESENTED AS PRESENT - TIME (t-21)\n",
    "\n",
    "# my_df.sort_values([\"feature\",\"time\"], ascending=[\"True\",\"True\"])\n",
    "my_df = my_df.sort_values([\"feature\",\"time\"], ascending=[\"True\",\"True\"]).reset_index(drop=True)\n",
    "display(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T18:32:42.942141Z",
     "start_time": "2021-09-02T18:32:42.229680Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,1,figsize=(8,8), sharex=True, sharey=True)\n",
    "\n",
    "axs[0].bar(my_df[\"time\"].iloc[:200],my_df[\"weight\"].iloc[:200])\n",
    "# axs[0].set_ylim([-0.15,0.15])\n",
    "axs[1].bar(my_df[\"time\"].iloc[201:],my_df[\"weight\"].iloc[201:])\n",
    "# axs[1].set_ylim([-0.15,0.15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley (SHAP) (keras model only)\n",
    "\n",
    "https://github.com/slundberg/shap#deep-learning-example-with-deepexplainer-tensorflowkeras-models\n",
    "\n",
    "https://shap-lrjball.readthedocs.io/en/latest/generated/shap.DeepExplainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T13:48:54.238203Z",
     "start_time": "2021-09-07T13:47:15.110074Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "N = 1000\n",
    "idx_sample = np.random.randint(0,X.shape[0],N)\n",
    "X_background = X[idx_sample]\n",
    "# X_background = shap.maskers.Independent(X[idx_sample,:,:])\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.DeepExplainer(model, X_background)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T12:38:34.724427Z",
     "start_time": "2021-09-03T12:38:34.716983Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.force_plot(explainer.expected_value[0].numpy(), shap_values[0][0,:,0], X_test[0,:,0], matplotlib=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T14:18:39.022024Z",
     "start_time": "2021-09-07T14:18:37.819658Z"
    }
   },
   "outputs": [],
   "source": [
    "saveplot = 1\n",
    "\n",
    "ishap = 4\n",
    "label = labels[idx]\n",
    "shap.summary_plot(shap_values[ishap][:,:], X_test[:,:], feature_names=feature_names,\n",
    "#                   plot_type=\"bar\",\n",
    "                  max_display=20,\n",
    "                  show=False\n",
    "                 )\n",
    "if saveplot:\n",
    "    plt.savefig(f'../results/shap_values/swarmplot_sv_mlp_{labels[idxs[ishap]][2:]}.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T14:18:44.149587Z",
     "start_time": "2021-09-07T14:18:42.665288Z"
    }
   },
   "outputs": [],
   "source": [
    "saveplot = 1\n",
    "\n",
    "fig,axs = plt.subplots(2,1,figsize=(8,8), sharex=True, sharey=True)\n",
    "x_plot = np.arange(0,1000,5)\n",
    "y1_plot = np.abs(shap_values[ishap][:,:200]).mean(axis=0)\n",
    "y2_plot = np.abs(shap_values[ishap][:,200:]).mean(axis=0)\n",
    "axs[0].bar(x_plot,y1_plot,width=5)\n",
    "axs[0].set_ylabel(\"Feature importance\")\n",
    "axs[1].bar(x_plot,y2_plot,width=5)\n",
    "axs[1].set_ylabel(\"Feature importance\")\n",
    "axs[1].set_xlabel(\"time (ms)\")\n",
    "\n",
    "if saveplot:\n",
    "    plt.savefig(f\"../results/shap_values/barplot_sv_mlp_{labels[idxs[ishap]][2:]}_both.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation feature importance (sklearn model only)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T13:17:18.073949Z",
     "start_time": "2021-09-08T13:16:11.686556Z"
    }
   },
   "outputs": [],
   "source": [
    "scorer = \"neg_mean_squared_error\"\n",
    "\n",
    "result = permutation_importance(model, X_test, y_test,\n",
    "                           n_repeats=5,\n",
    "                           random_state=0,\n",
    "                           scoring=scorer,\n",
    "                           n_jobs=None\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T13:18:22.580105Z",
     "start_time": "2021-09-08T13:18:22.574220Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../results/permutation_importance/permutation_mse_mlp.txt\",\"w+\") as f:\n",
    "    for i in result.importances_mean.argsort()[::-1]:\n",
    "        if result.importances_mean[i] - 2 * result.importances_std[i] > 0:\n",
    "            f.write(f\"{feature_names[i]:<8} \"\n",
    "                  f\"{result.importances_mean[i]:.4f}\"\n",
    "                  f\" +/- {result.importances_std[i]:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T13:18:33.258536Z",
     "start_time": "2021-09-08T13:18:30.645945Z"
    }
   },
   "outputs": [],
   "source": [
    "saveit = 1\n",
    "\n",
    "importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(14,10), sharex=False, sharey=True)\n",
    "importances.iloc[:200].plot.bar(yerr=result.importances_std[:200], ax=axs[0], width=1, rot=45)\n",
    "importances.iloc[200:].plot.bar(yerr=result.importances_std[200:], ax=axs[1], width=1, rot=45)\n",
    "# ax.set_title(\"Feature importances using permutation on full model\")\n",
    "axs[0].set_ylabel(\"Mean decrease\")\n",
    "axs[1].set_ylabel(\"Mean decrease\")\n",
    "tick_spacing = 10\n",
    "axs[0].xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "axs[1].xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "fig.tight_layout()\n",
    "\n",
    "if saveit:\n",
    "    plt.savefig(\"../results/permutation_importance/barplot_mse_mlp_all.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature drop-out\n",
    "\n",
    "For user-defined segments of the feature vector in a test dataset, set values in segment to zero or mean and calculate resulting score metric (MAE, R2). Compare to score metric with full feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T14:45:25.789915Z",
     "start_time": "2021-09-07T14:45:25.502085Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, list MAE and R2 reference values using complete feature set\n",
    "\n",
    "n_segments = 6\n",
    "X_repeat = drop_features(X_test, n_segments, dropval=\"mean\")\n",
    "r2_out = list()\n",
    "mae_out = list()\n",
    "for i,X_rep in enumerate(X_repeat):\n",
    "    print('Dropout segment %d'%(i+1))\n",
    "    y_hat = model.predict(X_rep)\n",
    "    mae_all = mean_absolute_error(y_test, y_hat)\n",
    "    mae = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "    r2 = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "    r2_all = r2_score(y_test,y_hat)\n",
    "    r2_out.append(np.append(r2,r2_all))\n",
    "    mae_out.append(np.append(mae,mae_all))\n",
    "    print([labels[i] for i in idxs])\n",
    "    print(mae_all)\n",
    "    print(mae)\n",
    "    print(r2_all)\n",
    "    print(r2)\n",
    "    print('\\n')\n",
    "    \n",
    "y_hat = model.predict(X_test)\n",
    "mae_all_0 = mean_absolute_error(y_test, y_hat)\n",
    "mae_0 = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "print('Reference metrics:')\n",
    "print(mae_all_0)\n",
    "print(mae_0)\n",
    "print(r2_score(y_test,y_hat))\n",
    "print(r2_score(y_test,y_hat,multioutput='raw_values'))\n",
    "print('\\n')\n",
    "\n",
    "df_out = pd.DataFrame(data=mae_out,columns=[labels[i] for i in idxs]+[\"overall\"])\n",
    "df_out.set_index(np.arange(1,n_segments+1),inplace=True)\n",
    "df_out.loc[0]=np.append(mae_0,mae_all_0)\n",
    "df_out.sort_index().to_csv(f'../results/feature_drop/feature_drop_mean_MLP_mae_n{n_segments}.csv',float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T15:15:06.228287Z",
     "start_time": "2021-09-07T15:15:04.886081Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot change in MAE from reference (no feature dropout)\n",
    "mae_diff = df_out.loc[1:6].values-df_out.loc[0].values\n",
    "\n",
    "fig,axs=plt.subplots(2,3, figsize=(12,8), sharex=True, sharey=True)\n",
    "axs=axs.flatten()\n",
    "for ch in range(mae_diff.shape[1]):\n",
    "#     axs[ch].grid()\n",
    "    xplot = np.arange(1,7)\n",
    "    axs[ch].bar(xplot,mae_diff[:,ch])\n",
    "#     axs[ch].set_ylim([mae_diff.min()-0.01,mae_diff.max()+0.01])\n",
    "    axs[ch].set_xticks(xplot)\n",
    "    if ch<5:\n",
    "        axs[ch].set_title(f\"$\\lambda$_{labels[idxs[ch]][2:]}\")\n",
    "    else:\n",
    "        axs[ch].set_title(\"Overall\")\n",
    "\n",
    "# axis labels\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Dropped segment', ylabel='Difference in MAE')\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.savefig(\"../results/feature_drop/bar_diff_mae_MLP.png\",dpi=200,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "405.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "661px",
    "left": "2139px",
    "right": "20px",
    "top": "120px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
