{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:48:08.153447Z",
     "start_time": "2021-12-15T14:48:05.149384Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, RepeatedKFold, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalAveragePooling1D, AveragePooling1D\n",
    "from tensorflow.keras.layers import Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['savefig.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:48:42.698802Z",
     "start_time": "2021-12-15T14:48:42.665548Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'tf.test.is_built_with_cuda(): {tf.test.is_built_with_cuda()}');\n",
    "# print(f'tf.test.is_gpu_available(): {tf.test.is_gpu_available()}')\n",
    "\n",
    "if tf.__version__[0] == '1':\n",
    "    print(f'tf.config.experimental_list_devices(): {tf.config.experimental_list_devices()}');\n",
    "else:\n",
    "    print(f'tf.config.list_physical_devices(\"GPU\"): {tf.config.list_physical_devices(\"GPU\")}');\n",
    "    \n",
    "print(f'tf.test.gpu_device_name(): {tf.test.gpu_device_name()}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:48:45.084141Z",
     "start_time": "2021-12-15T14:48:45.081454Z"
    }
   },
   "outputs": [],
   "source": [
    "randst = np.random.randint(0,100)\n",
    "print(randst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:51:48.874074Z",
     "start_time": "2021-12-15T14:51:48.869681Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_my_results(results_mae, results_mae_per, results_r2, results_r2_per):\n",
    "    \n",
    "    print('MAE:')\n",
    "    print('\\t%.3f (%.3f) overall' % (np.mean(results_mae), np.std(results_mae)))\n",
    "    for mae,std,idx in zip(np.mean(results_mae_per, axis=0), np.std(results_mae_per, axis=0), idx_params):\n",
    "        print('\\t%.3f (%.3f) %s' % (mae, std, labels[idx]) )\n",
    "    print('R2:')\n",
    "    print('\\t%.3f (%.3f) overall' %(np.mean(results_r2), np.std(results_r2)))\n",
    "    for r2,std,idx in zip(np.mean(results_r2_per, axis=0), np.std(results_r2_per, axis=0), idx_params):\n",
    "        print('\\t%.3f (%.3f) %s' % (r2, std, labels[idx]) )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and partition data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and test case indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:48:53.193425Z",
     "start_time": "2021-12-15T14:48:53.035706Z"
    }
   },
   "outputs": [],
   "source": [
    "name = \"n4130\"\n",
    "here = Path.cwd()\n",
    "data_path = Path(here.joinpath(f\"data/data_control_{name}.h5\"))\n",
    "\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    Datasetnames=f.keys()\n",
    "    print(*list(Datasetnames), sep = \"\\n\")\n",
    "    trace = f['trace'][:,:200,:] # select time 0-200\n",
    "    t = f['time'][...]\n",
    "    adj_factors = f['adjustment_factors'][...]\n",
    "    cost_terms = f['cost_terms'][...]\n",
    "    \n",
    "if trace.shape[0] != adj_factors.shape[0]:\n",
    "    print('Number of samples do not match for trace and adj_factors!')\n",
    "\n",
    "print(\"Number of traces:\", trace.shape[0])\n",
    "labels = [\"g_Kr\",\"g_CaL\",\"lambda_B\",\"g_NaCa\",\"g_K1\",\"J_SERCA_bar\",\"lambda_diff\",\"lambda_RyR\",\"g_bCa\",\"g_Na\",\"g_NaL\"]\n",
    "\n",
    "idx_all = list(np.arange(0,trace.shape[0]))\n",
    "idx_test = list(np.loadtxt(here.joinpath(\"data/idx_key_p11_s100_n5000_ns50.txt\"), dtype=int))\n",
    "idx_train = list(set(idx_all) - set(idx_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition data\n",
    "Test cases are pre-selected for out-of-sample testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:48:57.275527Z",
     "start_time": "2021-12-15T14:48:57.266628Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_params = [0,1,4,9,10]\n",
    "trace_train = trace[idx_train,:,:]\n",
    "trace_test = trace[idx_test,:,:]\n",
    "af_train = adj_factors[idx_train,:][:,idx_params]\n",
    "af_test = adj_factors[idx_test,:][:,idx_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning for kNN, RF, SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:49:01.423628Z",
     "start_time": "2021-12-15T14:49:01.395702Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "y = af_train\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:51:00.863278Z",
     "start_time": "2021-12-15T14:49:06.713858Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_grid = {\"n_neighbors\": np.arange(1, 20),\n",
    "            \"weights\": ['uniform', 'distance'],\n",
    "            \"p\": [1,2],\n",
    "              }\n",
    "\n",
    "knn_base = KNeighborsRegressor()\n",
    "knn_gscv = GridSearchCV(estimator = knn_base, param_grid = knn_grid,\n",
    "                        cv=5, verbose=2,\n",
    "                        n_jobs=-1)\n",
    "knn_gscv.fit(X, y)\n",
    "\n",
    "print(knn_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T17:51:01.386012Z",
     "start_time": "2021-12-09T17:51:01.376614Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "y = af_train\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T18:17:14.465205Z",
     "start_time": "2021-12-09T17:55:23.624866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
    "rf_n_estimators.append(1500)\n",
    "rf_n_estimators.append(2000)\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 55, 6)]\n",
    "rf_max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "rf_max_features = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Criterion to split on\n",
    "rf_criterion = ['mae']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
    "\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'bootstrap': rf_bootstrap}\n",
    "\n",
    "rf_base = RandomForestRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "rf_gscv = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, \n",
    "                               n_iter=10, cv = 5, verbose = 2,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_gscv.fit(X, y)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "rf_gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:52:26.230086Z",
     "start_time": "2021-12-15T14:52:26.203987Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "y = af_train\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T18:46:55.322735Z",
     "start_time": "2021-12-09T18:46:45.918309Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma_range = list(np.logspace(-6, 3, 9))\n",
    "gamma_range.append(\"scale\")\n",
    "gamma_range.append(\"auto\")\n",
    "\n",
    "\n",
    "svr_grid = {\"estimator__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "            \"estimator__gamma\": [\"scale\", \"auto\"],\n",
    "            \"estimator__C\": [1, 10, 100, 1000],\n",
    "            \"estimator__epsilon\": [0.001,0.01,0.1,1,10],\n",
    "            \"estimator__shrinking\": [True, False]\n",
    "           }\n",
    "\n",
    "svr_base = MultiOutputRegressor(SVR())\n",
    "svr_gscv = GridSearchCV(estimator = svr_base, param_grid = svr_grid,\n",
    "                        cv=3, verbose=2,\n",
    "                        n_jobs=-1)\n",
    "svr_gscv.fit(X, y)\n",
    "\n",
    "print(svr_gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models using k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:51:11.602994Z",
     "start_time": "2021-12-15T14:51:11.594286Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "y = af_train\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:51:14.308445Z",
     "start_time": "2021-12-15T14:51:14.302525Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_knn(**kwargs):\n",
    "    model = KNeighborsRegressor(**kwargs,\n",
    "                               n_jobs=-1)\n",
    "    return model\n",
    "\n",
    "def evaluate_model_knn(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # define model\n",
    "        model = get_model_knn(**knn_gscv.best_params_)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model on test set\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:51:55.960977Z",
     "start_time": "2021-12-15T14:51:53.649733Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_knn(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (stop-start))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:35:34.134144Z",
     "start_time": "2021-12-09T14:35:34.131666Z"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:42:31.306513Z",
     "start_time": "2021-09-21T14:42:31.297762Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "y = af_train\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model using best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:42:33.422909Z",
     "start_time": "2021-09-21T14:42:33.415618Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_rfr(**kwargs):\n",
    "    model = RandomForestRegressor(**kwargs)\n",
    "    return model\n",
    "\n",
    "def evaluate_model_rfr(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # define model\n",
    "        model = get_model_rfr(**rf_gscv.best_params_)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model on test set\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:54:38.001053Z",
     "start_time": "2021-09-21T14:42:37.900687Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_rfr(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:59:41.853461Z",
     "start_time": "2021-09-21T14:59:41.844118Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "y = af_train\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T14:59:51.066419Z",
     "start_time": "2021-09-21T14:59:51.058248Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_svr(**kwargs):\n",
    "    svr = SVR(**kwargs)\n",
    "\n",
    "    model = MultiOutputRegressor(svr)\n",
    "    return model\n",
    "\n",
    "def evaluate_model_svr(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # define model\n",
    "        model = get_model_svr(**svr_gscv.best_params_)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model on test set\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T15:10:10.439455Z",
     "start_time": "2021-09-21T15:00:45.616919Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_svr(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:52:56.976417Z",
     "start_time": "2021-12-15T14:52:56.968146Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "y = af_train\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:53:06.656248Z",
     "start_time": "2021-12-15T14:53:06.648264Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_mlp1(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=n_inputs, kernel_initializer='he_uniform', activation=activations.swish))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=\"mae\")\n",
    "    return model\n",
    "\n",
    "def get_model_mlp3(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=n_inputs, kernel_initializer='he_uniform', activation=activations.swish))\n",
    "    model.add(Dense(500, activation=activations.swish))\n",
    "    model.add(Dense(500, activation=activations.swish))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=\"mae\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model_mlp(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    mlp_trained = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        model = get_model_mlp3(n_inputs, n_outputs) # <<<<< SPECIFY WHICH MLP MODEL\n",
    "        mlp_trained.append( model.fit(X_train, y_train, verbose=0, epochs=200) )\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per, mlp_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T14:58:28.805841Z",
     "start_time": "2021-12-15T14:53:40.416468Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_mlp(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T15:50:32.970217Z",
     "start_time": "2021-09-21T15:50:32.962679Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.copy(trace_train)\n",
    "y = af_train\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T15:51:19.811387Z",
     "start_time": "2021-09-21T15:51:19.800921Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_cnn(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, input_shape=n_inputs))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation=activations.swish))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def evaluate_model_cnn(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    cnn_trained = list()\n",
    "    n_inputs, n_outputs = X.shape[1:], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        scalers = {}\n",
    "        for i in range(X_train.shape[2]):\n",
    "            scalers[i] = StandardScaler()\n",
    "            X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "        for i in range(X_test.shape[2]):\n",
    "            X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])\n",
    "        model = get_model_cnn(n_inputs, n_outputs)\n",
    "        cnn_trained.append(model.fit(X_train, y_train, verbose=0, epochs=200))\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T17:04:07.476798Z",
     "start_time": "2021-09-21T15:51:22.261620Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_cnn(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Convolutional Neural Networks (FCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T10:01:13.488378Z",
     "start_time": "2021-09-22T10:01:13.444713Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.copy(trace_train)\n",
    "y = af_train\n",
    "\n",
    "print('X shape:',X.shape)\n",
    "print('Feature shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T10:01:14.834544Z",
     "start_time": "2021-09-22T10:01:14.811270Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_fcn(n_inputs, n_outputs):\n",
    "    x = keras.layers.Input(n_inputs)\n",
    "    drop_out = Dropout(0.1)(x)\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=8, input_shape=n_inputs, padding='same')(x) # default filter 128\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activations.swish)(conv1)\n",
    "\n",
    "    drop_out = Dropout(0.1)(conv1)\n",
    "    conv2 = keras.layers.Conv1D(filters=128, kernel_size=5, padding='same')(conv1) # default filter 256\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.Activation(activations.swish)(conv2)\n",
    "\n",
    "    drop_out = Dropout(0.1)(conv2)\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding='same')(conv2) # default filter 128\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.Activation(activations.swish)(conv3)\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "#     full = keras.layers.GlobalMaxPooling1D()(conv3)\n",
    "    out = keras.layers.Dense(n_outputs)(full)\n",
    "    model = keras.models.Model(inputs=x, outputs=out)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def get_model_fcn_2(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=128, kernel_size=8, input_shape=n_inputs, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=256, kernel_size=5, input_shape=n_inputs, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, input_shape=n_inputs, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "#     model.add(MaxPooling1D())\n",
    "#     model.add(AveragePooling1D())\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "    \n",
    "def evaluate_model_fcn(X, y):\n",
    "    results_mae = list()\n",
    "    results_mae_per = list()\n",
    "    results_r2 = list()\n",
    "    results_r2_per = list()\n",
    "    fcn_trained = list()\n",
    "    n_inputs, n_outputs = X.shape[1:], y.shape[1]\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=randst)\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        X_train, X_test = X[train_ix,:,:], X[test_ix,:,:]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        nbatch, n_time, n_channel  = X_train.shape[0], X_train.shape[1], X_train.shape[2]\n",
    "        scalers = {}\n",
    "        for i in range(X_train.shape[2]):\n",
    "            scalers[i] = StandardScaler()\n",
    "            X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "        for i in range(X_test.shape[2]):\n",
    "            X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])\n",
    "        model = get_model_fcn(n_inputs, n_outputs)\n",
    "        fcn_trained.append(model.fit(X_train, y_train, verbose=0, epochs=200))\n",
    "        y_hat = model.predict(X_test)\n",
    "        r2_per = r2_score(y_test,y_hat,multioutput='raw_values')\n",
    "        r2 = r2_score(y_test,y_hat)\n",
    "        mae = mean_absolute_error(y_test, y_hat)\n",
    "        mae_per = mean_absolute_error(y_test, y_hat, multioutput='raw_values')\n",
    "        print('>%.3f' % mae)\n",
    "        results_mae.append(mae)\n",
    "        results_mae_per.append(mae_per)\n",
    "        results_r2.append(r2)\n",
    "        results_r2_per.append(r2_per)\n",
    "    return results_mae, results_mae_per, results_r2, results_r2_per\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T12:56:38.365031Z",
     "start_time": "2021-09-22T10:01:19.382214Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results_mae, results_mae_per, results_r2, results_r2_per = evaluate_model_fcn(X, y)\n",
    "stop = time.time()\n",
    "print('Time of execution: %f' % (np.divide(stop-start, 60)))\n",
    "\n",
    "print_my_results(results_mae, results_mae_per, results_r2, results_r2_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final train and evaluation on target test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "X_test = np.concatenate((trace_test[:,:,0],trace_test[:,:,1]),axis=1)\n",
    "y_train = af_train\n",
    "y_test = af_test\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transformformsform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_knn()\n",
    "\n",
    "t_train_start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "t_train_stop = time.time()\n",
    "\n",
    "t_test_start = time.time()\n",
    "y_hat = model.predict(X_test)\n",
    "t_test_stop = time.time()\n",
    "\n",
    "print(\"Time to train model: \", t_train_stop-t_train_start)\n",
    "print(\"Time to test model: \", t_test_stop-t_test_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "X_test = np.concatenate((trace_test[:,:,0],trace_test[:,:,1]),axis=1)\n",
    "y_train = af_train\n",
    "y_test = af_test\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_rfr()\n",
    "\n",
    "t_train_start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "t_train_stop = time.time()\n",
    "\n",
    "t_test_start = time.time()\n",
    "y_hat = model.predict(X_test)\n",
    "t_test_stop = time.time()\n",
    "\n",
    "print(\"Time to train model: \", t_train_stop-t_train_start)\n",
    "print(\"Time to test model: \", t_test_stop-t_test_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "X_test = np.concatenate((trace_test[:,:,0],trace_test[:,:,1]),axis=1)\n",
    "y_train = af_train\n",
    "y_test = af_test\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_svr()\n",
    "\n",
    "t_train_start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "t_train_stop = time.time()\n",
    "\n",
    "t_test_start = time.time()\n",
    "y_hat = model.predict(X_test)\n",
    "t_test_stop = time.time()\n",
    "\n",
    "print(\"Time to train model: \", t_train_stop-t_train_start)\n",
    "print(\"Time to test model: \", t_test_stop-t_test_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((trace_train[:,:,0],trace_train[:,:,1]),axis=1)\n",
    "X_test = np.concatenate((trace_test[:,:,0],trace_test[:,:,1]),axis=1)\n",
    "y_train = af_train\n",
    "y_test = af_test\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X_train.shape[1], y_train.shape[1]\n",
    "\n",
    "model = get_model_mlp1(n_inputs, n_outputs)\n",
    "\n",
    "t_train_start = time.time()\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "t_train_stop = time.time()\n",
    "\n",
    "t_test_start = time.time()\n",
    "y_hat = model.predict(X_test)\n",
    "t_test_stop = time.time()\n",
    "\n",
    "print(\"Time to train model: \", t_train_stop-t_train_start)\n",
    "print(\"Time to test model: \", t_test_stop-t_test_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trace_train\n",
    "X_test = trace_test\n",
    "y_train = af_train\n",
    "y_test = af_test\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X_train.shape[1:], y_train.shape[1]\n",
    "\n",
    "model = get_model_cnn(n_inputs, n_outputs)\n",
    "\n",
    "t_train_start = time.time()\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "t_train_stop = time.time()\n",
    "\n",
    "t_test_start = time.time()\n",
    "y_hat = model.predict(X_test)\n",
    "t_test_stop = time.time()\n",
    "\n",
    "print(\"Time to train model: \", t_train_stop-t_train_start)\n",
    "print(\"Time to test model: \", t_test_stop-t_test_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trace_train\n",
    "X_test = trace_test\n",
    "y_train = af_train\n",
    "y_test = af_test\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i])\n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs, n_outputs = X_train.shape[1:], y_train.shape[1]\n",
    "\n",
    "model = get_model_fcn(n_inputs, n_outputs)\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "y_hat = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
